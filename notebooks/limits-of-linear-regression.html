
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Tutorial: More on linear models &#8212; Data explorations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/limits-of-linear-regression';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Discussion questions" href="../discussions/limits-of-linear-regression.html" />
    <link rel="prev" title="Limits and variations of linear regression" href="../lectures/limits-of-linear-regression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/information.png" class="logo__image only-light" alt="Data explorations - Home"/>
    <script>document.write(`<img src="../_static/information.png" class="logo__image only-dark" alt="Data explorations - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Data explorations
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Information and Meaning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/quantitative-epistemology.html">Quantitative epsitemology</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="quantitative-epistemology.html">Tutorial: Getting started</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/quantitative-epistemology.html">Discussion questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/the-value-of-openness.html">The value of openness</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="the-value-of-openness.html">Tutorial: Repositories and version control</a></li>




<li class="toctree-l2"><a class="reference internal" href="../discussions/the-value-of-openness.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/01_the-value-of-openness.html">Exercise 1: Github &amp; Jupyter</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/what-is-a-theory.html">What is a theory?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../discussions/what-is-a-theory.html">Discussion questions</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/models-as-testable-hypotheses.html">Models as testable hypotheses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="models-as-testable-hypotheses.html">Tutorial: Introduction to R, functions, and good coding habits</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/models-as-testable-hypotheses.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/02_models-as-testable-hypotheses.html">Exercise 2: Coding Habits &amp; Functions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/data-as-objects-and-architectures.html">Data as objects and architectures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="data-as-objects-and-architectures.html">Tutorial: Data as Objects and Tidy Data</a></li>


<li class="toctree-l2"><a class="reference internal" href="../discussions/data-as-objects-and-architectures.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/data-as-objects-and-architectures.html">Exercise 3: Data objects</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/techniques-for-data-cleansing.html">Techniques for data cleansing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="techniques-for-data-cleansing.html">Tutorial: Data Cleansing and the Tidyverse</a></li>




<li class="toctree-l2"><a class="reference internal" href="../discussions/techniques-for-data-cleansing.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/techniques-for-data-cleansing.html">Exercise 4: Data cleansing</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/visualization-as-analysis.html">Visualization as analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="visualization-as-analysis.html">Tutorial: Basics of plotting</a></li>

<li class="toctree-l2"><a class="reference internal" href="../discussions/visualization-as-analysis.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/visualization-as-analysis.html">Exercise 5: Using ggplot</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/visualization-through-human-eyes.html">Visualization through human eyes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="visualization-through-human-eyes.html">Tutorial: More advanced plotting</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/visualization-through-human-eyes.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/visualization-through-human-eyes.html">Exercise 6: More plotting options</a></li>


</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Knowledge</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/statistical-learning-theory.html">The bias-variance tradeoff</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../discussions/statistical-learning-theory.html">Discussion questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/linear-models.html">Linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear-models.html">Tutorial: Refresher on working with matrices</a></li>






<li class="toctree-l2"><a class="reference internal" href="../discussions/linear-models.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/linear-models.html">Exercise 7:  Linear models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/the-ordinary-least-squares-solution.html">The ordinary least squares solution</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="the-ordinary-least-squares-solution.html">Tutorial: Refresher for solving oridinary least squares</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/the-ordinary-least-squares-solution.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/the-ordinary-least-squares-solution.html">Exercise 8:  Linear models, continued</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../lectures/limits-of-linear-regression.html">Limits and variations of linear regression</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial: More on linear models</a></li>




<li class="toctree-l2"><a class="reference internal" href="../discussions/limits-of-linear-regression.html">Discussion questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/classifiers.html">Classifiers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="classifiers.html">Tutorial: Basics classifiers</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/classifiers.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/classifiers.html">Exercise 9: Classification</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/mixed-effects-models.html">Mixed effects models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixed-effects-models.html">Tutorial: Running linear mixed effects models</a></li>

<li class="toctree-l2"><a class="reference internal" href="../discussions/mixed-effects-models.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/mixed-effects-models.html">Exercise 10: Mixed effects</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/the-beauty-of-knn.html">The beauty of kNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="the-beauty-of-knn.html">Tutorial: Running kNN models</a></li>

<li class="toctree-l2"><a class="reference internal" href="../discussions/the-beauty-of-knn.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/the-beauty-of-knn.html">Exercise 11: The beauty of kNN</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/cross-validation.html">Cross validation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross-validation.html">Tutorial: Implementing cross validation</a></li>




<li class="toctree-l2"><a class="reference internal" href="../discussions/cross-validation.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/cross-validation.html">Exercise 12: Cross validation</a></li>




</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/resampling-methods.html">Resampling methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="resampling-methods.html">Tutorial: Boostrap and permutation tests</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/resampling-methods.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/resampling-methods.html">Exercise 13:  Resampling methods</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/mediation-and-moderation.html">Mediation and moderation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mediation-and-moderation.html">Tutorial: Running mediation and moderation models</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/mediation-and-moderation.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/mediation-and-moderation.html">Exercise 14: Mediation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/power-analysis-via-simulations.html">Power analysis via simulations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="power-analysis-via-simulations.html">Tutorial: Running basic power analyses</a></li>


<li class="toctree-l2"><a class="reference internal" href="../discussions/power-analysis-via-simulations.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/power-analysis-via-simulations.html">Exercise 15: Power analyses</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/selecting-the-best-model.html">Selecting the best model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="selecting-the-best-model.html">Tutorial: Model selection</a></li>

<li class="toctree-l2"><a class="reference internal" href="../discussions/selecting-the-best-model.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/selecting-the-best-model.html">Exercise 16: Model selection</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/regularized-regression.html">Regularized regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="regularized-regression.html">Tutorial: Basic ridge and LASSO models</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/regularized-regression.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/regularized-regression.html">Exercise 17: Regularized regression</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/principal-component-methods.html">Principal component methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="principal-component-methods.html">Tutorial: Basic PCA approaches</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/principal-component-methods.html">Discussion questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/principal-component-methods.html">Exercise 18: Principal component methods</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Understanding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/reconsidering-the-p-value.html">Reconsidering the p-value</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../discussions/reconsidering-the-p-value.html">Discussion questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/bayes-factor-accepting-the-null.html">Bayes factor</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayes-factor-accepting-the-null.html">Tutorial: Estimating Bayes factors</a></li>



<li class="toctree-l2"><a class="reference internal" href="../discussions/bayes-factor-accepting-the-null.html">Discussion questions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lectures/telling-your-data-story.html">Telling your data story</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../discussions/telling-your-data-story.html">Discussion questions</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/RobJavVar/DSPN_CourseNotebook/main?urlpath=tree/book/notebooks/limits-of-linear-regression.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/RobJavVar/DSPN_CourseNotebook/blob/main/book/notebooks/limits-of-linear-regression.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/limits-of-linear-regression.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tutorial: More on linear models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Tutorial: More on linear models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals">Goals:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting started</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-with-multiple-predictors">Regression with multiple predictors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-categorical-qualitative-predictors">Working with categorical (qualitative) predictors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-the-bias-variance-tradeoff">Simulating the bias-variance tradeoff</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tutorial-more-on-linear-models">
<h1>Tutorial: More on linear models<a class="headerlink" href="#tutorial-more-on-linear-models" title="Link to this heading">#</a></h1>
<p>In this tutorial, we will play more with linear regression models, including an illustration of the bias-variance tradeoff at the end.</p>
<section id="goals">
<h2>Goals:<a class="headerlink" href="#goals" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Regression with multiple predictors</p></li>
<li><p>Using categorical predictors</p></li>
<li><p>Simulating the bias-variance tradeoff</p></li>
</ul>
<p>This lab draws from the content in Chapters 2 &amp; 3 of James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2013). “An introduction to statistical learning: with applications in r.”</p>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="getting-started">
<h1>Getting started<a class="headerlink" href="#getting-started" title="Link to this heading">#</a></h1>
<p>Before we start, let’s just get all the libraries loaded up front. This tutorial requires some new libraries we haven’t worked with before. Uncomment the <em>install.packages</em> lines if you do not already have all the packages already installed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libaries to install</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;glmnet&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;matrixStats&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;denoiseR&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;gplots&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;RColorBrewer&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;plot3D&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;car&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ISLR&quot;</span><span class="p">)</span>

<span class="c1"># Load the libraries</span>
<span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">matrixStats</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">denoiseR</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gplots</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">RColorBrewer</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">plot3D</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ISLR</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

also installing the dependencies ‘iterators’, ‘foreach’, ‘shape’, ‘Rcpp’, ‘RcppEigen’


Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

also installing the dependencies ‘SparseM’, ‘MatrixModels’, ‘minqa’, ‘nloptr’, ‘later’, ‘lazyeval’, ‘carData’, ‘abind’, ‘pbkrtest’, ‘quantreg’, ‘lme4’, ‘htmlwidgets’, ‘httpuv’, ‘crosstalk’, ‘promises’, ‘estimability’, ‘numDeriv’, ‘mvtnorm’, ‘car’, ‘DT’, ‘ellipse’, ‘emmeans’, ‘flashClust’, ‘leaps’, ‘multcompView’, ‘scatterplot3d’, ‘ggrepel’, ‘irlba’, ‘FactoMineR’


Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

also installing the dependencies ‘bitops’, ‘gtools’, ‘caTools’


Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

also installing the dependency ‘misc3d’


Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)

Loading required package: Matrix

Loaded glmnet 4.1-8

── <span class=" -Color -Color-Bold">Attaching core tidyverse packages</span> ──────────────────────── tidyverse 2.0.0 ──
<span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">dplyr    </span> 1.1.4     <span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">readr    </span> 2.1.5
<span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">forcats  </span> 1.0.0     <span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">stringr  </span> 1.5.1
<span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">ggplot2  </span> 3.4.4     <span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">tibble   </span> 3.2.1
<span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">lubridate</span> 1.9.3     <span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">tidyr    </span> 1.3.1
<span class=" -Color -Color-Green">✔</span> <span class=" -Color -Color-Blue">purrr    </span> 1.0.2     
── <span class=" -Color -Color-Bold">Conflicts</span> ────────────────────────────────────────── tidyverse_conflicts() ──
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">tidyr</span>::<span class=" -Color -Color-Green">expand()</span> masks <span class=" -Color -Color-Blue">Matrix</span>::expand()
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">dplyr</span>::<span class=" -Color -Color-Green">filter()</span> masks <span class=" -Color -Color-Blue">stats</span>::filter()
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">dplyr</span>::<span class=" -Color -Color-Green">lag()</span>    masks <span class=" -Color -Color-Blue">stats</span>::lag()
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">tidyr</span>::<span class=" -Color -Color-Green">pack()</span>   masks <span class=" -Color -Color-Blue">Matrix</span>::pack()
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">dplyr</span>::<span class=" -Color -Color-Green">select()</span> masks <span class=" -Color -Color-Blue">MASS</span>::select()
<span class=" -Color -Color-Red">✖</span> <span class=" -Color -Color-Blue">tidyr</span>::<span class=" -Color -Color-Green">unpack()</span> masks <span class=" -Color -Color-Blue">Matrix</span>::unpack()
<span class=" -Color -Color-Cyan">ℹ</span> Use the conflicted package (<span class=" -Color -Color-Blue">&lt;http://conflicted.r-lib.org/&gt;</span>) to force all conflicts to become errors

Attaching package: ‘matrixStats’


The following object is masked from ‘package:dplyr’:

    count



Attaching package: ‘gplots’


The following object is masked from ‘package:stats’:

    lowess


Warning message:
“no DISPLAY variable so Tk is not available”
</pre></div>
</div>
</div>
</div>
<p>Because we will be generating random data here, let’s set the random number generator seed. This will allow us to get the same results everytime we run the entire notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the random number generator seed</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">2023</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="regression-with-multiple-predictors">
<h1>Regression with multiple predictors<a class="headerlink" href="#regression-with-multiple-predictors" title="Link to this heading">#</a></h1>
<br>
In the examples we have done so far, we have only looked at models where p = 1.
<div class="math notranslate nohighlight">
\[ Y_{medv} = \hat{\beta_0} + \hat{\beta_1}X_{lstat} + \epsilon \]</div>
<p>Now let us explore the case where p &gt; 1. For this we will be using the <code class="docutils literal notranslate"><span class="pre">Cars93</span></code> dataset which is part of the <code class="docutils literal notranslate"><span class="pre">MASS</span></code> package. This dataset has information on the dimensions and weight (<a class="reference external" href="https://www.rdocumentation.org/packages/MASS/versions/7.3-58.2/topics/Cars93">among other things</a>) for different types of cars.</p>
<p>Let’s just look at the data along the dimensions of width, length, and weight.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">scatter3D</span><span class="p">(</span><span class="n">Cars93</span><span class="o">$</span><span class="n">Width</span><span class="p">,</span><span class="w"> </span><span class="n">Cars93</span><span class="o">$</span><span class="n">Length</span><span class="p">,</span><span class="w"> </span><span class="n">Cars93</span><span class="o">$</span><span class="n">Weight</span><span class="p">,</span>
<span class="w">          </span><span class="n">phi</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="o">=</span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="c1">#phi controls tilt and theta controls angle</span>
<span class="w">          </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Width&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Length&quot;</span><span class="p">,</span><span class="n">zlab</span><span class="o">=</span><span class="s">&quot;Weight&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/e18aac658dba52cdd37dfc3a9f44438b66cbbdf09661a98e8a26a04bba1d9256.png"><img alt="../_images/e18aac658dba52cdd37dfc3a9f44438b66cbbdf09661a98e8a26a04bba1d9256.png" src="../_images/e18aac658dba52cdd37dfc3a9f44438b66cbbdf09661a98e8a26a04bba1d9256.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<p>Interpeting the 3 dimensional scatterplot is the same as interpreting a 2 dimensional plot. You want a “football” shaped clustering where changes in <code class="docutils literal notranslate"><span class="pre">Weight</span></code> follow changes in the other two variables. So here, as the width and length of the car increase, the weight of the car increases too.</p>
<p>So it looks like adding <code class="docutils literal notranslate"><span class="pre">Width</span></code> seems to also explain <code class="docutils literal notranslate"><span class="pre">Weight</span></code>. Let’s confirm by fitting a linear model with <code class="docutils literal notranslate"><span class="pre">Width</span></code> and <code class="docutils literal notranslate"><span class="pre">Length</span></code> predicting <code class="docutils literal notranslate"><span class="pre">Weight</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">lm.fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Weight</span><span class="o">~</span><span class="n">Width</span><span class="o">+</span><span class="n">Length</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">Cars93</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Weight ~ Width + Length, data = Cars93)

Residuals:
    Min      1Q  Median      3Q     Max 
-546.05 -194.89  -45.85  189.58  579.58 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -5999.519    540.622 -11.097  &lt; 2e-16 ***
Width         102.156     13.281   7.692 1.75e-11 ***
Length         10.836      3.437   3.153   0.0022 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 274 on 90 degrees of freedom
Multiple R-squared:  0.7889,	Adjusted R-squared:  0.7842 
F-statistic: 168.1 on 2 and 90 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Let’s say we wanted to estimate the <em>full model</em> (i.e., use all the numeric variables in the <code class="docutils literal notranslate"><span class="pre">Cars93</span></code> data set to predict <code class="docutils literal notranslate"><span class="pre">Weight</span></code>). If you use the “.” symbol in the <code class="docutils literal notranslate"><span class="pre">lm()</span></code> function call, it tells R to use all variables <em>but</em> the one being predicted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">num_cols</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">unlist</span><span class="p">(</span><span class="nf">lapply</span><span class="p">(</span><span class="n">Cars93</span><span class="p">,</span><span class="w"> </span><span class="n">is.numeric</span><span class="p">))</span><span class="w"> </span><span class="c1"># Find just the numeric columns</span>

<span class="n">lm.fit</span><span class="o">=</span><span class="nf">lm</span><span class="p">(</span><span class="n">Weight</span><span class="o">~</span><span class="n">.</span><span class="p">,</span>
<span class="w">          </span><span class="n">data</span><span class="o">=</span><span class="n">Cars93</span><span class="p">[,</span><span class="n">num_cols</span><span class="p">])</span><span class="w"> </span><span class="c1">#using indexing to select columns</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Weight ~ ., data = Cars93[, num_cols])

Residuals:
     Min       1Q   Median       3Q      Max 
-220.402  -70.076   -4.002   69.825  222.764 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         140.05133  658.01561   0.213  0.83213    
Min.Price           165.31369  266.93918   0.619  0.53792    
Price              -324.39700  532.71044  -0.609  0.54471    
Max.Price           161.71716  266.15830   0.608  0.54560    
MPG.city              8.59419    9.31530   0.923  0.35969    
MPG.highway         -20.22139    9.05965  -2.232  0.02912 *  
EngineSize          -54.32469   59.99456  -0.905  0.36860    
Horsepower            4.32739    0.90113   4.802 9.82e-06 ***
RPM                  -0.11785    0.05006  -2.354  0.02165 *  
Rev.per.mile         -0.11059    0.05473  -2.021  0.04751 *  
Fuel.tank.capacity   31.58016   11.17775   2.825  0.00629 ** 
Passengers          -12.18737   33.37579  -0.365  0.71620    
Length                5.60418    2.67397   2.096  0.04006 *  
Wheelbase            15.97271    6.32881   2.524  0.01410 *  
Width                 1.81074   10.88571   0.166  0.86841    
Turn.circle           8.29436    8.03511   1.032  0.30583    
Rear.seat.room       -0.53080    9.04313  -0.059  0.95338    
Luggage.room          6.06806    7.94515   0.764  0.44783    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 114.9 on 64 degrees of freedom
  (11 observations deleted due to missingness)
Multiple R-squared:  0.9674,	Adjusted R-squared:  0.9588 
F-statistic: 111.8 on 17 and 64 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Let’s just keep playing with the ways that you can run and query the model object. First, let’s say you want to exclude some of the non-significant variables from the model. According to the coefficients table above, <code class="docutils literal notranslate"><span class="pre">EngineSize</span></code> and <code class="docutils literal notranslate"><span class="pre">Passengers</span></code> are not significant predictors when we run the full model. So we can remove them in two ways.</p>
<p>First we can just train a new model with these variables excluded. You can do this by adding a <code class="docutils literal notranslate"><span class="pre">-</span></code> in front of the variable name after the tilde.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#excluding EngineSize and Passengers using &quot;-&quot;</span>
<span class="n">lm.fit_new</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Weight</span><span class="o">~</span><span class="n">.</span><span class="o">-</span><span class="n">EngineSize</span><span class="w"> </span><span class="o">-</span><span class="n">Passengers</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">Cars93</span><span class="p">[,</span><span class="n">num_cols</span><span class="p">])</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">lm.fit_new</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Weight ~ . - EngineSize - Passengers, data = Cars93[, 
    num_cols])

Residuals:
     Min       1Q   Median       3Q      Max 
-237.809  -68.733   -1.621   68.685  227.473 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         147.72555  651.85150   0.227  0.82142    
Min.Price            75.96356  249.11030   0.305  0.76137    
Price              -147.95766  497.76892  -0.297  0.76722    
Max.Price            74.20151  248.91613   0.298  0.76656    
MPG.city              7.03821    9.10838   0.773  0.44245    
MPG.highway         -19.32891    8.75157  -2.209  0.03068 *  
Horsepower            3.86820    0.69431   5.571 5.02e-07 ***
RPM                  -0.08711    0.03597  -2.422  0.01819 *  
Rev.per.mile         -0.09151    0.05010  -1.826  0.07232 .  
Fuel.tank.capacity   29.29317   10.63264   2.755  0.00758 ** 
Length                5.43428    2.61187   2.081  0.04135 *  
Wheelbase            15.52055    6.25976   2.479  0.01572 *  
Width                -0.16370   10.61106  -0.015  0.98774    
Turn.circle           8.52630    7.96200   1.071  0.28813    
Rear.seat.room       -3.78306    7.61133  -0.497  0.62082    
Luggage.room          5.43697    7.79114   0.698  0.48773    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 114 on 66 degrees of freedom
  (11 observations deleted due to missingness)
Multiple R-squared:  0.9669,	Adjusted R-squared:  0.9594 
F-statistic: 128.7 on 15 and 66 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Alternatively we can just update the <em>lm.fit</em> model that we estimated above by extracting those variables using the <em>update</em> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Or just update the existing model</span>
<span class="n">lm.fit_new</span><span class="o">=</span><span class="nf">update</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">,</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="o">-</span><span class="n">EngineSize</span><span class="w"> </span><span class="o">-</span><span class="n">Passengers</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">lm.fit_new</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Weight ~ Min.Price + Price + Max.Price + MPG.city + 
    MPG.highway + Horsepower + RPM + Rev.per.mile + Fuel.tank.capacity + 
    Length + Wheelbase + Width + Turn.circle + Rear.seat.room + 
    Luggage.room, data = Cars93[, num_cols])

Residuals:
     Min       1Q   Median       3Q      Max 
-237.809  -68.733   -1.621   68.685  227.473 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         147.72555  651.85150   0.227  0.82142    
Min.Price            75.96356  249.11030   0.305  0.76137    
Price              -147.95766  497.76892  -0.297  0.76722    
Max.Price            74.20151  248.91613   0.298  0.76656    
MPG.city              7.03821    9.10838   0.773  0.44245    
MPG.highway         -19.32891    8.75157  -2.209  0.03068 *  
Horsepower            3.86820    0.69431   5.571 5.02e-07 ***
RPM                  -0.08711    0.03597  -2.422  0.01819 *  
Rev.per.mile         -0.09151    0.05010  -1.826  0.07232 .  
Fuel.tank.capacity   29.29317   10.63264   2.755  0.00758 ** 
Length                5.43428    2.61187   2.081  0.04135 *  
Wheelbase            15.52055    6.25976   2.479  0.01572 *  
Width                -0.16370   10.61106  -0.015  0.98774    
Turn.circle           8.52630    7.96200   1.071  0.28813    
Rear.seat.room       -3.78306    7.61133  -0.497  0.62082    
Luggage.room          5.43697    7.79114   0.698  0.48773    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 114 on 66 degrees of freedom
  (11 observations deleted due to missingness)
Multiple R-squared:  0.9669,	Adjusted R-squared:  0.9594 
F-statistic: 128.7 on 15 and 66 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Either way it’s pretty easy to swap terms in and out of the model in R.</p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="working-with-categorical-qualitative-predictors">
<h1>Working with categorical (qualitative) predictors<a class="headerlink" href="#working-with-categorical-qualitative-predictors" title="Link to this heading">#</a></h1>
<p>So far we’ve been playing mostly with quantitative predictors. Let’s now play with some categorical, i.e., qualitative predictors.</p>
<p>For this we will use the <code class="docutils literal notranslate"><span class="pre">Carseats</span></code> data set from the <a class="reference external" href="https://cran.r-project.org/web/packages/car/car.pdf">car</a> package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># First we will want to clear the workspace</span>
<span class="nf">rm</span><span class="p">(</span><span class="n">list</span><span class="o">=</span><span class="nf">ls</span><span class="p">())</span>

<span class="c1"># Look at the Carseats dataset</span>
<span class="c1"># help(Carseats) # Uncomment to view documentation</span>
<span class="nf">names</span><span class="p">(</span><span class="n">Carseats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>'Sales'</li><li>'CompPrice'</li><li>'Income'</li><li>'Advertising'</li><li>'Population'</li><li>'Price'</li><li>'ShelveLoc'</li><li>'Age'</li><li>'Education'</li><li>'Urban'</li><li>'US'</li></ol>
</div></div>
</div>
<p>This data set consists of a data frame with 400 observations on the following 11 variables.</p>
<ul class="simple">
<li><p><strong>Sales:</strong>  Unit sales (in thousands) at each location</p></li>
<li><p><strong>CompPrice:</strong> Price charged by competitor at each location</p></li>
<li><p><strong>Income:</strong>  Community income level (in thousands of dollars)</p></li>
<li><p><strong>Advertising:</strong> Local advertising budget for company at each location (in thousands of dollars)</p></li>
<li><p><strong>Population:</strong> Population size in region (in thousands)</p></li>
<li><p><strong>Price:</strong>  Price company charges for car seats at each site</p></li>
<li><p><strong>ShelveLoc:</strong> A factor with levels Bad, Good and Medium indicating the quality of the shelving location for the car seats at each site</p></li>
<li><p><strong>Age:</strong> Average age of the local population</p></li>
<li><p><strong>Education:</strong> Education level at each location</p></li>
<li><p><strong>Urban:</strong>  A factor with levels No and Yes to indicate whether the store is in an urban or rural location</p></li>
<li><p><strong>US:</strong> A factor with levels No and Yes to indicate whether the store is in the US or not</p></li>
</ul>
<p>Let’s fit a model that predicts <code class="docutils literal notranslate"><span class="pre">Sales</span></code> from some of these variables. We will want to pay special attention to the <code class="docutils literal notranslate"><span class="pre">ShelveLoc</span></code> variable.</p>
<p>The below model includes all the individual predictors (using <code class="docutils literal notranslate"><span class="pre">.</span></code>), and also fits some interaction terms using the <code class="docutils literal notranslate"><span class="pre">:</span></code> between two variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">lm.fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Sales</span><span class="o">~</span><span class="n">.</span><span class="o">+</span><span class="n">Income</span><span class="o">:</span><span class="n">Advertising</span><span class="o">+</span><span class="n">Price</span><span class="o">:</span><span class="n">Age</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">Carseats</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.9208 -0.7503  0.0177  0.6754  3.3413 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***
CompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***
Income              0.0108940  0.0026044   4.183 3.57e-05 ***
Advertising         0.0702462  0.0226091   3.107 0.002030 ** 
Population          0.0001592  0.0003679   0.433 0.665330    
Price              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***
ShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***
ShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***
Age                -0.0579466  0.0159506  -3.633 0.000318 ***
Education          -0.0208525  0.0196131  -1.063 0.288361    
UrbanYes            0.1401597  0.1124019   1.247 0.213171    
USYes              -0.1575571  0.1489234  -1.058 0.290729    
Income:Advertising  0.0007510  0.0002784   2.698 0.007290 ** 
Price:Age           0.0001068  0.0001333   0.801 0.423812    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.011 on 386 degrees of freedom
Multiple R-squared:  0.8761,	Adjusted R-squared:  0.8719 
F-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16
</pre></div>
</div>
</div>
</div>
<p>Let’s look closer at the <em>ShelveLoc</em> variable. Notice that the original variable had 3 levels. But R automatically recoded this into 2 binary variables: <em>ShelveLocGood</em> and <em>ShelveLocMedium</em>.</p>
<p>You can see how r sets up this binarization using the <em>contrasts</em> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">contrasts</span><span class="p">(</span><span class="n">Carseats</span><span class="o">$</span><span class="n">ShelveLoc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="dataframe">
<caption>A matrix: 3 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>Good</th><th scope=col>Medium</th></tr>
</thead>
<tbody>
	<tr><th scope=row>Bad</th><td>0</td><td>0</td></tr>
	<tr><th scope=row>Good</th><td>1</td><td>0</td></tr>
	<tr><th scope=row>Medium</th><td>0</td><td>1</td></tr>
</tbody>
</table>
</div></div>
</div>
<p>Here, the <code class="docutils literal notranslate"><span class="pre">Shelveloc</span></code> value is “Bad” when both “Good” and “Medium” are 0. The value is “Good” when <code class="docutils literal notranslate"><span class="pre">Good</span> <span class="pre">=</span> <span class="pre">1</span></code>, and is “Medium” when <code class="docutils literal notranslate"><span class="pre">Medium</span> <span class="pre">=</span> <span class="pre">1</span></code></p>
<p>Thus the effect for “bad” shelving locations is included in the <strong>intercept term</strong> of the model. The coefficient for <code class="docutils literal notranslate"><span class="pre">ShelveLocGood</span></code> in the above output therefore represents the bump in sales associated with having “good” shelving locations compared to “bad” shelving locations, all other variables held constant. (And same thing for <code class="docutils literal notranslate"><span class="pre">ShelveLocMedium</span></code> – this is the difference between “bad” and “medium” shelving locations.)</p>
<p>In this model, <code class="docutils literal notranslate"><span class="pre">ShelveLoc</span></code> is the only categorical variable that has more than 2 levels. But remember – things get complicated if you have multiple categorical variables that have more than two terms. As we discussed in lecture, in those cases the intercept no longer corresponds to a single level of a categorical variable. So watch carefully how R redefines categorical variables.</p>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="simulating-the-bias-variance-tradeoff">
<h1>Simulating the bias-variance tradeoff<a class="headerlink" href="#simulating-the-bias-variance-tradeoff" title="Link to this heading">#</a></h1>
<p>For the last part of this tutorial, let us return to the bias-variance tradeoff. Our goal will be to simulate data in order to show the tradeoff in action.</p>
<p>To do this we need to generate a data set that has a natural low-dimensional structure to it. Which means that if you have <span class="math notranslate nohighlight">\(p\)</span> variables in <span class="math notranslate nohighlight">\(X\)</span>, because of correlations across variables, the true dimensionality of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(&lt;p\)</span>.</p>
<p>You don’t need to know the details of <em>how</em> the data that we generate is low-dimensional (we will return to this issue when we talk about principal componenet models). For right now all you’ll need to know is the concept of a matrix “rank”.</p>
<p>When we talk about a matrix’s “rank” we mean essentially the number of independent columns in the matrix. If each column is linearly independent of every other column in <span class="math notranslate nohighlight">\(X\)</span>, then the rank of <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(k\)</span>, is <span class="math notranslate nohighlight">\(k=p\)</span>. We call this situation being “full rank”. As <span class="math notranslate nohighlight">\(X\)</span> gets greater correlational structure across variables (columns), the rank decreases. We say it is “low rank”.</p>
<p>For doing this we will use the <em>LRsim</em> function in the <em>denoiseR</em> libary that you loaded above. Let us write a simple function that will generate data by taking 4 inputs.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> = number of observations (rows)</p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span> = number of features (columns)</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span> = rank of data</p></li>
<li><p><span class="math notranslate nohighlight">\(s\)</span> = signal-to-noise ratio</p></li>
</ul>
<p>We will rely on something called singular value decomposition (SVD) to create a low rank data set. You don’t need to know what SVD does at the moment. We will come back to this in later classes. For now, just trust us that it generates low rank, (i.e. intercorrelated) data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">make_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">){</span>

<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">p</span><span class="p">){</span>
<span class="w">    </span><span class="c1"># If number of features is greater</span>
<span class="w">    </span><span class="c1"># than number of observations, increase</span>
<span class="w">    </span><span class="c1"># observations for the PCA to work</span>
<span class="w">    </span><span class="n">m</span><span class="o">=</span><span class="n">p</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Otheriwse use the input n</span>
<span class="w">    </span><span class="n">m</span><span class="o">=</span><span class="n">n</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Make full rank until p=k</span>
<span class="w">    </span><span class="c1"># degree_diff = k-p</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">LRsim</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">s</span><span class="p">)</span><span class="o">$</span><span class="n">X</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">LRsim</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">)</span><span class="o">$</span><span class="n">X</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1"># Recover low-d components</span>
<span class="w">  </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">princomp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># Set the first k components to 1, otherwise 0</span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">){</span>
<span class="w">    </span><span class="n">u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="c1">#rnorm(p,mean=1,sd=0.5)</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="n">k</span><span class="p">),</span><span class="nf">matrix</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">nrow</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">ncol</span><span class="o">=</span><span class="n">p</span><span class="o">-</span><span class="n">k</span><span class="p">))</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1"># Calculate the weights in the data space</span>
<span class="w">  </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">t</span><span class="p">(</span><span class="n">u</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="nf">t</span><span class="p">(</span><span class="n">z</span><span class="o">$</span><span class="n">loadings</span><span class="p">))</span>

<span class="w">  </span><span class="c1"># In case we needed to set m=p for the</span>
<span class="w">  </span><span class="c1"># PCA to work, take the first n observations</span>
<span class="w">  </span><span class="c1"># of x</span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">,]</span>

<span class="w">  </span><span class="c1"># Generate your output</span>
<span class="w">  </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="w">  </span><span class="kr">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="o">=</span><span class="n">b</span><span class="p">))</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Pay attention to how we set up the relationship with <span class="math notranslate nohighlight">\(Y\)</span>. The vector <span class="math notranslate nohighlight">\(u\)</span> only assigns strongest weights to the first <span class="math notranslate nohighlight">\(k\)</span> components in <span class="math notranslate nohighlight">\(X\)</span> in order to influence <span class="math notranslate nohighlight">\(Y\)</span>. So the dimensionality of our problem is approximately <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Okay, now that we have our function for making data, let’s take a look at what it returns for a 100 observations (<span class="math notranslate nohighlight">\(n\)</span>), 20 variables (<span class="math notranslate nohighlight">\(p\)</span>), a rank (<span class="math notranslate nohighlight">\(k\)</span>) of 5, and signal-to-noise (<span class="math notranslate nohighlight">\(s\)</span>) of 10.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span>
<span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span>
<span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span>
<span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span>

<span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">make_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">Y</span><span class="o">~</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = Y ~ X, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.78569 -0.62726 -0.07531  0.59695  2.57939 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)    0.03523    0.04533   0.777   0.4375  
X1            24.41500   61.86812   0.395   0.6933  
X2            14.17653   44.10736   0.321   0.7480  
X3            17.62072   67.64961   0.260   0.7946  
X4          -110.45193   71.72453  -1.540   0.1242  
X5            32.11625   54.66273   0.588   0.5571  
X6           133.22155   66.01748   2.018   0.0442 *
X7           -86.10253   55.68913  -1.546   0.1227  
X8          -116.70388   67.10784  -1.739   0.0827 .
X9           108.78295   69.26610   1.571   0.1170  
X10           42.71434   59.53488   0.717   0.4734  
X11          -66.51462   62.53258  -1.064   0.2880  
X12           63.94582   80.68294   0.793   0.4284  
X13            9.71852   56.98526   0.171   0.8647  
X14           -3.02868   55.56074  -0.055   0.9566  
X15          -58.80215   64.89896  -0.906   0.3654  
X16          106.39623   64.93919   1.638   0.1020  
X17           45.76793   66.71295   0.686   0.4930  
X18           36.66511   66.41676   0.552   0.5812  
X19           17.25835   70.65191   0.244   0.8071  
X20           65.65573   59.36835   1.106   0.2693  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.003 on 479 degrees of freedom
Multiple R-squared:  0.1889,	Adjusted R-squared:  0.155 
F-statistic: 5.577 on 20 and 479 DF,  p-value: 5.266e-13
</pre></div>
</div>
</div>
</div>
<p>You will notice that only few of the <span class="math notranslate nohighlight">\(p\)</span> variables are “statistically significance” because <span class="math notranslate nohighlight">\(X\)</span> really has a lower dimensionality of 10 (<span class="math notranslate nohighlight">\(k=10\)</span>) and we only set these few components to have an effect on <span class="math notranslate nohighlight">\(Y\)</span>. This is sort of what we would expect.</p>
<p>Now we can visualize the correlational structure of our data set. Here we’ll use single-linkage clustering for illustrative purposes. For this we will rely on the <em>heatmap.2</em> function from the <em>gplots</em> package that you loaded above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">heatmap.2</span><span class="p">(</span><span class="nf">cor</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">),</span><span class="n">col</span><span class="o">=</span><span class="nf">brewer.pal</span><span class="p">(</span><span class="m">11</span><span class="p">,</span><span class="s">&quot;RdBu&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">trace</span><span class="o">=</span><span class="s">&quot;none&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="n">key.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">key.ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">key.xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Correlation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/99d666602005bf3b5a537da102c1a096f16a811586af24aa85056d193cc3a937.png"><img alt="../_images/99d666602005bf3b5a537da102c1a096f16a811586af24aa85056d193cc3a937.png" src="../_images/99d666602005bf3b5a537da102c1a096f16a811586af24aa85056d193cc3a937.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<p>Notice that there are a lot of non-zero off diagonal values in this correlation matrix. This means that there is rich correlational structure in <span class="math notranslate nohighlight">\(X\)</span> as expected.</p>
<p>For comparison, take a look at what a full rank version of <span class="math notranslate nohighlight">\(X\)</span> looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span>
<span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">make_data</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="nf">heatmap.2</span><span class="p">(</span><span class="nf">cor</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">),</span><span class="n">col</span><span class="o">=</span><span class="nf">brewer.pal</span><span class="p">(</span><span class="m">11</span><span class="p">,</span><span class="s">&quot;RdBu&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">trace</span><span class="o">=</span><span class="s">&quot;none&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="n">key.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">key.ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">key.xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Correlation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/53e730b587a004b402ac2f3994cded7e97df3acee8789e075dfb587cc40da178.png"><img alt="../_images/53e730b587a004b402ac2f3994cded7e97df3acee8789e075dfb587cc40da178.png" src="../_images/53e730b587a004b402ac2f3994cded7e97df3acee8789e075dfb587cc40da178.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<p>Notice the difference? There is very little correlational structure here because each column in <span class="math notranslate nohighlight">\(X\)</span> is independent of the other.</p>
<p>Now we want to write a simple loop that uses the built-in <code class="docutils literal notranslate"><span class="pre">lm</span></code> function in R to fit the data that we generate. We already went over this a little bit in previous tutorials. Here we want to focus on how to write a simple loop that generates a training and test data set for different values of <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>This function will be simple. We will generate one large data set (<span class="math notranslate nohighlight">\(n*2\)</span> observations) and do a split half test for evaluating both training and test accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">## ------------------------------</span>
<span class="c1"># LM split validation function</span>
<span class="c1">## ------------------------------</span>
<span class="n">bv_lm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">degree</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Set up the arrays for storing the results</span>
<span class="w">    </span><span class="n">train_rss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="n">degree</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">test_rss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="n">degree</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="n">p_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">degree</span><span class="p">[</span><span class="nf">length</span><span class="p">(</span><span class="n">degree</span><span class="p">)]</span>

<span class="w">    </span><span class="c1"># Loop through for each set of p-features</span>
<span class="w">    </span><span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="n">degree</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1"># Set up the data, split into training and test</span>
<span class="w">        </span><span class="c1"># sets of size n</span>
<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">make_data</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="m">2</span><span class="p">,</span><span class="n">p_max</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>

<span class="w">        </span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="m">1</span><span class="o">:</span><span class="n">p</span><span class="p">],</span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="o">$</span><span class="n">Y</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">])</span>
<span class="w">        </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">[(</span><span class="n">n</span><span class="m">+1</span><span class="p">)</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">),</span><span class="m">1</span><span class="o">:</span><span class="n">p</span><span class="p">],</span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="o">$</span><span class="n">Y</span><span class="p">[(</span><span class="n">n</span><span class="m">+1</span><span class="p">)</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="p">)])</span>

<span class="w">        </span><span class="c1"># Use simple GLM</span>
<span class="w">        </span><span class="n">lm.fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">)</span><span class="w"> </span><span class="c1">#, subset=set_id)</span>

<span class="w">        </span><span class="c1"># Get your model prediction on both the training</span>
<span class="w">        </span><span class="c1"># and test sets</span>
<span class="w">        </span><span class="n">yhat_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">)</span>
<span class="w">        </span><span class="n">yhat_test</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Because we get weird outlier predictions plot median sum square error</span>
<span class="w">        </span><span class="n">train_rss</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="n">degree</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="m">+1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">median</span><span class="p">((</span><span class="n">train</span><span class="o">$</span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">yhat_train</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="w">        </span><span class="n">test_rss</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="n">degree</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="m">+1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">median</span><span class="p">((</span><span class="n">test</span><span class="o">$</span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">yhat_test</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1"># Store the RSS in a data frame</span>
<span class="w">    </span><span class="n">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">degree</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">=</span><span class="n">train_rss</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">=</span><span class="n">test_rss</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Notice what this function does. It loops through list called <em>degrees</em> that samples a range of <span class="math notranslate nohighlight">\(p\)</span> from that list. Even though the underlying dimensionality is the same.</p>
<p>Okay now we can do one run of this new function to see how it works and plot the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span>
<span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span>
<span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span>
<span class="n">degree</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">20</span><span class="p">)</span>

<span class="n">bv_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">bv_lm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">degree</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">)</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">bv_df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;Median sum squared error&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;p&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/3f614811d2084b17b29a82f8ac54025fbbffa23a93ff572db36e207d8dcc8b9e.png"><img alt="../_images/3f614811d2084b17b29a82f8ac54025fbbffa23a93ff572db36e207d8dcc8b9e.png" src="../_images/3f614811d2084b17b29a82f8ac54025fbbffa23a93ff572db36e207d8dcc8b9e.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<p>It is noisy, but you should notice that the test error skyrockets as <span class="math notranslate nohighlight">\(p\)</span> gets larger. If you squint, somewhere around <span class="math notranslate nohighlight">\(p=12\)</span> the test error is minimized. If you run this multiple times, you’ll get slightly different plots because the data is getting randomly simulated each time.</p>
<p>But to get a clearer look, let’s run a large number of sims and average together.</p>
<p>(This step takes about 10 minutes or so to run if you execute it on your own)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">warn</span><span class="o">=</span><span class="m">-1</span><span class="p">)</span>

<span class="c1"># Parameters</span>
<span class="n">n_iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2000</span>
<span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span>
<span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span>
<span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span>
<span class="n">degree</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">20</span><span class="p">)</span>

<span class="c1"># Aggregated output</span>
<span class="n">train_rss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">NA</span><span class="p">,</span><span class="n">nrow</span><span class="o">=</span><span class="nf">length</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span><span class="n">ncol</span><span class="o">=</span><span class="n">n_iter</span><span class="p">)</span>
<span class="n">test_rss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">NA</span><span class="p">,</span><span class="n">nrow</span><span class="o">=</span><span class="nf">length</span><span class="p">(</span><span class="n">degree</span><span class="p">),</span><span class="n">ncol</span><span class="o">=</span><span class="n">n_iter</span><span class="p">)</span>

<span class="c1"># Loop through n_iter times</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_iter</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">bv_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">bv_lm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">degree</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>
<span class="w">  </span><span class="n">train_rss</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">bv_df</span><span class="o">$</span><span class="n">train</span>
<span class="w">  </span><span class="n">test_rss</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="n">bv_df</span><span class="o">$</span><span class="n">test</span>
<span class="p">}</span>

<span class="c1"># Make a new data frame for plotting</span>
<span class="n">run_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">degree</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">=</span><span class="nf">rowMeans</span><span class="p">(</span><span class="n">train_rss</span><span class="p">),</span><span class="w"> </span><span class="n">test</span><span class="o">=</span><span class="nf">rowMeans</span><span class="p">(</span><span class="n">test_rss</span><span class="p">),</span>
<span class="w">                    </span><span class="n">strain</span><span class="o">=</span><span class="nf">rowSds</span><span class="p">(</span><span class="n">train_rss</span><span class="p">),</span><span class="w"> </span><span class="n">stest</span><span class="o">=</span><span class="nf">rowSds</span><span class="p">(</span><span class="n">test_rss</span><span class="p">))</span>

<span class="c1"># Plot</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">run_df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">p</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s">&quot;steelblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="o">=</span><span class="s">&quot;twodash&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;Median sum squared error&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;p&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/c2cf8221c3af38a28aef7265bf79b16a5e0d353dfffff9e1ab7f7e57169144de.png"><img alt="../_images/c2cf8221c3af38a28aef7265bf79b16a5e0d353dfffff9e1ab7f7e57169144de.png" src="../_images/c2cf8221c3af38a28aef7265bf79b16a5e0d353dfffff9e1ab7f7e57169144de.png" style="width: 420px; height: 420px;" />
</a>
</div>
</div>
<p>In the plot above, the red line shows the test error and the blue dashed line shows the training error. Notice the classic bias-variance tradeoff where training error continues to decrease as <span class="math notranslate nohighlight">\(p\)</span> increases, but test error has a “U” shape that bottoms out close to <span class="math notranslate nohighlight">\(p=k\)</span>. Classic bias-variance tradeoff.</p>
<p>If you want to have fun with this effect, try changing the value of <span class="math notranslate nohighlight">\(k\)</span> in the code cells above and re-running the simulation. What happens?</p>
<p><em>Notebook authored by Tim Verstynen and Ven Popov, edited by Krista Bond, Charles Wu, Patience Stevens, Amy Sentis, and Fiona Horner.</em></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../lectures/limits-of-linear-regression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Limits and variations of linear regression</p>
      </div>
    </a>
    <a class="right-next"
       href="../discussions/limits-of-linear-regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Discussion questions</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Tutorial: More on linear models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals">Goals:</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting started</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-with-multiple-predictors">Regression with multiple predictors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-categorical-qualitative-predictors">Working with categorical (qualitative) predictors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-the-bias-variance-tradeoff">Simulating the bias-variance tradeoff</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Roberto Vargas, Timothy Verstynen, Venn Popov, Krista Bond, Charles Wu, Patience Stevens, Amy Sentis, Fiona Horner
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>